{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96663387",
   "metadata": {},
   "source": [
    "# Using pyAerial to evaluate a PUSCH neural receiver\n",
    "This example shows how to use the pyAerial cuPHY Python bindings to evaluate a trained neural network -based PUSCH receiver. In this example, the neural network is used to replace channel estimation, noise and interference estimation and channel equalization, and thus outputs\n",
    "log-likelihood ratios directly. The model is a variant of what has been proposed in\n",
    "\n",
    "S. Cammerer, F. AÃ¯t Aoudia, J. Hoydis, A. Oeldemann, A. Roessler, T. Mayer and A. Keller, \"[A Neural Receiver for 5G NR Multi-user MIMO](https://arxiv.org/abs/2312.02601)\", IEEE Globecom Workshops (GC Wkshps), Dec. 2023.\n",
    "\n",
    "The rest of the PUSCH receiver pipeline following the neural receiver, meaning LDPC decoding chain, is modeled using pyAerial. Also, the neural receiver takes LS channel estimates as inputs in addition to the received PUSCH slot.\n",
    "These are also obtained using pyAerial. The neural receiver -based PUSCH receiver is compared against the conventional PUSCH receiver, which is built using pyAerial's (fully fused) PUSCH pipeline. \n",
    "\n",
    "PUSCH transmitter is emulated by PDSCH transmission with properly chosen parameters, that way making it a 5G NR compliant PUSCH transmission. The NVIDIA [Sionna](https://nvlabs.github.io/sionna/) library is utilized for simulating the radio channel based on 3GPP channel models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab2c67d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d794a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from collections import defaultdict\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"3\"  # Silence TensorFlow.\n",
    "os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
    "\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import sionna\n",
    "import tensorflow as tf\n",
    "\n",
    "from aerial.phy5g.pdsch import PdschTx\n",
    "from aerial.phy5g.pusch import PuschRx\n",
    "from aerial.phy5g.algorithms import ChannelEstimator\n",
    "from aerial.phy5g.algorithms import TrtEngine\n",
    "from aerial.phy5g.algorithms import TrtTensorPrms\n",
    "from aerial.phy5g.ldpc import get_mcs\n",
    "from aerial.phy5g.ldpc import random_tb\n",
    "from aerial.phy5g.ldpc import get_tb_size\n",
    "from aerial.phy5g.ldpc import LdpcDeRateMatch\n",
    "from aerial.phy5g.ldpc import LdpcDecoder\n",
    "from aerial.phy5g.ldpc import CrcChecker\n",
    "from aerial.pycuphy.types import PuschLdpcKernelLaunch\n",
    "from aerial.phy5g.config import PuschConfig\n",
    "from aerial.phy5g.config import PuschUeConfig\n",
    "from aerial.util.cuda import get_cuda_stream\n",
    "from simulation_monitor import SimulationMonitor\n",
    "\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed.\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu.\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6c5c44",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "Set simulation parameters, numerology, PUSCH parameters and channel parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5cc239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters.\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "try:\n",
    "    import cupy as _cp\n",
    "    _cp.random.seed(random_seed)\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    tf.random.set_seed(random_seed)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "esno_db_range = np.arange(-4.0, -2.8, 0.2)\n",
    "num_slots = 10000\n",
    "min_num_tb_errors = 250\n",
    "\n",
    "# Numerology and frame structure. See TS 38.211.\n",
    "num_ofdm_symbols = 14\n",
    "fft_size = 4096\n",
    "cyclic_prefix_length = 288\n",
    "subcarrier_spacing = 30e3\n",
    "num_guard_subcarriers = (410, 410)\n",
    "num_slots_per_frame = 20\n",
    "\n",
    "# System/gNB configuration\n",
    "num_tx_ant = 1             # UE antennas\n",
    "num_rx_ant = 4             # gNB antennas\n",
    "cell_id = 41               # Physical cell ID\n",
    "enable_pusch_tdi = 1       # Enable time interpolation for equalizer coefficients\n",
    "eq_coeff_algo = 1          # Equalizer algorithm\n",
    "\n",
    "# PUSCH parameters\n",
    "rnti = 1234                # UE RNTI\n",
    "scid = 0                   # DMRS scrambling ID\n",
    "data_scid = 0              # Data scrambling ID\n",
    "layers = 1                 # Number of layers\n",
    "mcs_index = 7              # MCS index as per TS 38.214 table.\n",
    "mcs_table = 0              # MCS table index\n",
    "dmrs_ports = 1             # Used DMRS port.\n",
    "start_prb = 0              # Start PRB index.\n",
    "num_prbs = 273             # Number of allocated PRBs.\n",
    "start_sym = 0              # Start symbol index.\n",
    "num_symbols = 12           # Number of symbols.\n",
    "dmrs_scrm_id = 41          # DMRS scrambling ID\n",
    "dmrs_syms = [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0]  # Indicates which symbols are used for DMRS.\n",
    "dmrs_max_len = 1\n",
    "dmrs_add_ln_pos = 2\n",
    "num_dmrs_cdm_grps_no_data = 2\n",
    "mod_order, code_rate = get_mcs(mcs_index, mcs_table+1)  # Different indexing for MCS table.\n",
    "tb_size = get_tb_size(  # TB size in bits\n",
    "    mod_order=mod_order,\n",
    "    code_rate=code_rate,\n",
    "    dmrs_syms=dmrs_syms,\n",
    "    num_prbs=num_prbs,\n",
    "    start_sym=start_sym,\n",
    "    num_symbols=num_symbols,\n",
    "    num_layers=layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250b23b3-4a4f-4510-a20e-bad9a4a98681",
   "metadata": {},
   "source": [
    "## Create the model file for the TRT engine\n",
    "The TRT engine is built based on TensorRT plan files which are not portable across different platforms. Hence the plan file is created here from a supplied ONNX file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab521f74-45c4-4b5c-b377-bf707ef30140",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"../models\"\n",
    "nrx_onnx_file = f\"{MODEL_DIR}/neural_rx.onnx\"\n",
    "nrx_trt_file = f\"{MODEL_DIR}/neural_rx.trt\"\n",
    "command = f\"trtexec \" + \\\n",
    "    f\"--onnx={nrx_onnx_file} \" + \\\n",
    "    f\"--saveEngine={nrx_trt_file} \" + \\\n",
    "    f\"--skipInference \" + \\\n",
    "    f\"--inputIOFormats=fp32:chw,fp32:chw,fp32:chw,fp32:chw,fp32:chw,int32:chw,int32:chw \" + \\\n",
    "    f\"--outputIOFormats=fp32:chw,fp32:chw \" + \\\n",
    "    f\"--shapes=rx_slot_real:1x3276x12x4,rx_slot_imag:1x3276x12x4,h_hat_real:1x4914x1x4,h_hat_imag:1x4914x1x4 \" + \\\n",
    "    f\"> /dev/null\"\n",
    "return_val = os.system(command)\n",
    "if return_val == 0:\n",
    "    print(\"TRT engine model created.\")\n",
    "else:\n",
    "    raise SystemExit(\"Failed to create the TRT engine file!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d595a95",
   "metadata": {},
   "source": [
    "## Create the PUSCH pipelines\n",
    "As mentioned, PUSCH transmission is emulated here by the PDSCH transmission chain. Note that the static cell parameters and static PUSCH parameters are given upon creating the PUSCH transmission/reception objects. Dynamically (per slot) changing parameters are however set when actually running the transmission/reception, see further below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ac2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pusch_tx = PdschTx(\n",
    "    cell_id=cell_id,\n",
    "    num_rx_ant=num_tx_ant,\n",
    "    num_tx_ant=num_tx_ant,\n",
    ")\n",
    "\n",
    "# This is the fully fused PUSCH receiver chain.\n",
    "pusch_rx = PuschRx(\n",
    "    cell_id=cell_id,\n",
    "    num_rx_ant=num_rx_ant, \n",
    "    num_tx_ant=num_rx_ant,\n",
    "    enable_pusch_tdi=enable_pusch_tdi,\n",
    "    eq_coeff_algo=eq_coeff_algo,\n",
    "    # To make this equal separate PUSCH Rx components configuration:\n",
    "    ldpc_kernel_launch=PuschLdpcKernelLaunch.PUSCH_RX_LDPC_STREAM_SEQUENTIAL\n",
    ")\n",
    "\n",
    "# PUSCH configuration object. Note that default values are used for some parameters\n",
    "# not given here.\n",
    "pusch_ue_config = PuschUeConfig(\n",
    "    scid=scid,\n",
    "    layers=layers,\n",
    "    dmrs_ports=dmrs_ports,\n",
    "    rnti=rnti,\n",
    "    data_scid=data_scid,\n",
    "    mcs_table=mcs_table,\n",
    "    mcs_index=mcs_index,\n",
    "    code_rate=int(code_rate * 10),\n",
    "    mod_order=mod_order,\n",
    "    tb_size=tb_size // 8\n",
    ")\n",
    "# Note that this is a list. One UE group only in this case.\n",
    "pusch_configs = [PuschConfig(\n",
    "    ue_configs=[pusch_ue_config],\n",
    "    num_dmrs_cdm_grps_no_data=num_dmrs_cdm_grps_no_data,\n",
    "    dmrs_scrm_id=dmrs_scrm_id,\n",
    "    start_prb=start_prb,\n",
    "    num_prbs=num_prbs,\n",
    "    dmrs_syms=dmrs_syms,\n",
    "    dmrs_max_len=dmrs_max_len,\n",
    "    dmrs_add_ln_pos=dmrs_add_ln_pos,\n",
    "    start_sym=start_sym,\n",
    "    num_symbols=num_symbols\n",
    ")]\n",
    "\n",
    "\n",
    "class NeuralRx:\n",
    "    \"\"\"PUSCH neural receiver class.\n",
    "    \n",
    "    This class encapsulates the PUSCH neural receiver chain built using\n",
    "    pyAerial components.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_rx_ant,\n",
    "                 enable_pusch_tdi,\n",
    "                 eq_coeff_algo):\n",
    "        \"\"\"Initialize the neural receiver.\"\"\"\n",
    "        self.cuda_stream = get_cuda_stream()\n",
    "\n",
    "        # Build the components of the receiver. The channel estimator outputs just the LS\n",
    "        # channel estimates.\n",
    "        self.channel_estimator = ChannelEstimator(\n",
    "            num_rx_ant=num_rx_ant,\n",
    "            ch_est_algo=3,  # This is LS channel estimation.\n",
    "            cuda_stream=self.cuda_stream\n",
    "        )\n",
    "\n",
    "        # Create the pyAerial TRT engine object. This wraps TensorRT and links it together\n",
    "        # with the rest of cuPHY. Here pyAerial's Python bindings to the engine are used\n",
    "        # to run inference with the neural receiver model.\n",
    "        # The inputs of the neural receiver are:\n",
    "        # - LS channel estimates\n",
    "        # - The Rx slot\n",
    "        # - Active DMRS ports (active layers out of the layers that the neural receiver supports)\n",
    "        # - DMRS OFDM symbol locations (indices)\n",
    "        # - DMRS subcarrier positions within a PRB (indices)        \n",
    "        # Note that the shapes are given without batch size.\n",
    "        self.trt_engine = TrtEngine(\n",
    "            trt_model_file=\"../models/neural_rx.trt\",\n",
    "            max_batch_size=1,\n",
    "            input_tensors=[TrtTensorPrms('rx_slot_real', (3276, 12, 4), np.float32),\n",
    "                           TrtTensorPrms('rx_slot_imag', (3276, 12, 4), np.float32),\n",
    "                           TrtTensorPrms('h_hat_real', (4914, 1, 4), np.float32),\n",
    "                           TrtTensorPrms('h_hat_imag', (4914, 1, 4), np.float32),\n",
    "                           TrtTensorPrms('active_dmrs_ports', (1,), np.float32),\n",
    "                           TrtTensorPrms('dmrs_ofdm_pos', (3,), np.int32),\n",
    "                           TrtTensorPrms('dmrs_subcarrier_pos', (6,), np.int32)],\n",
    "            output_tensors=[TrtTensorPrms('output_1', (8, 1, 3276, 12), np.float32),\n",
    "                            TrtTensorPrms('output_2', (1, 3276, 12, 8), np.float32)]\n",
    "        )\n",
    "\n",
    "        # LDPC (de)rate matching and decoding implemented using pyAerial.\n",
    "        self.derate_match = LdpcDeRateMatch(\n",
    "            enable_scrambling=True,\n",
    "            cuda_stream=self.cuda_stream\n",
    "        )\n",
    "        self.decoder = LdpcDecoder(cuda_stream=self.cuda_stream)\n",
    "        self.crc_checker = CrcChecker(cuda_stream=self.cuda_stream)\n",
    "    \n",
    "    def run(\n",
    "        self,\n",
    "        rx_slot,\n",
    "        slot,\n",
    "        pusch_configs=pusch_configs\n",
    "    ):\n",
    "        \"\"\"Run the receiver.\"\"\"\n",
    "        # Channel estimation.\n",
    "        ch_est = self.channel_estimator.estimate(\n",
    "            rx_slot=rx_slot,\n",
    "            slot=slot,\n",
    "            pusch_configs=pusch_configs\n",
    "        )\n",
    "\n",
    "        # This is the neural receiver part. \n",
    "        # It outputs the LLRs for all symbols.\n",
    "        dmrs_ofdm_pos = np.where(np.array(pusch_configs[0].dmrs_syms))[0].astype(np.int32)\n",
    "        dmrs_ofdm_pos = dmrs_ofdm_pos[None, ...]\n",
    "        dmrs_subcarrier_pos = np.array([[0, 2, 4, 6, 8, 10]], dtype=np.int32)\n",
    "        active_dmrs_ports = np.ones((1, 1), dtype=np.float32)\n",
    "        rx_slot_in = rx_slot[None, :, pusch_configs[0].start_sym:pusch_configs[0].start_sym+pusch_configs[0].num_symbols, :]\n",
    "        ch_est_in = np.transpose(ch_est[0], (0, 3, 1, 2)).reshape(ch_est[0].shape[0] * ch_est[0].shape[3], ch_est[0].shape[1], ch_est[0].shape[2])\n",
    "        ch_est_in = ch_est_in[None, ...]\n",
    "        input_tensors = {\n",
    "            \"rx_slot_real\": np.real(rx_slot_in).astype(np.float32),\n",
    "            \"rx_slot_imag\": np.imag(rx_slot_in).astype(np.float32),\n",
    "            \"h_hat_real\": np.real(ch_est_in).astype(np.float32),\n",
    "            \"h_hat_imag\": np.imag(ch_est_in).astype(np.float32),\n",
    "            \"active_dmrs_ports\": active_dmrs_ports.astype(np.float32),\n",
    "            \"dmrs_ofdm_pos\": dmrs_ofdm_pos.astype(np.int32),\n",
    "            \"dmrs_subcarrier_pos\": dmrs_subcarrier_pos.astype(np.int32)\n",
    "        }\n",
    "        outputs = self.trt_engine.run(input_tensors)\n",
    "        \n",
    "        # The neural receiver outputs some values also for DMRS symbols, remove those\n",
    "        # from the output.\n",
    "        data_syms = np.array(pusch_configs[0].dmrs_syms[pusch_configs[0].start_sym:pusch_configs[0].start_sym + pusch_configs[0].num_symbols]) == 0\n",
    "        llrs = np.take(outputs[\"output_1\"][0, ...], np.where(data_syms)[0], axis=3)\n",
    "        \n",
    "        coded_blocks = self.derate_match.derate_match(\n",
    "            input_llrs=[llrs],\n",
    "            pusch_configs=pusch_configs\n",
    "        )\n",
    "    \n",
    "        code_blocks = self.decoder.decode(\n",
    "            input_llrs=coded_blocks,\n",
    "            pusch_configs=pusch_configs\n",
    "        )\n",
    "\n",
    "        decoded_tbs, _ = self.crc_checker.check_crc(\n",
    "            input_bits=code_blocks,\n",
    "            pusch_configs=pusch_configs\n",
    "        )\n",
    "\n",
    "        return decoded_tbs\n",
    "\n",
    "neural_rx = NeuralRx(\n",
    "    num_rx_ant=num_rx_ant, \n",
    "    enable_pusch_tdi=enable_pusch_tdi,\n",
    "    eq_coeff_algo=eq_coeff_algo\n",
    ")\n",
    "code\n",
    "python\n",
    "# Grouped configuration dict to pass to SimulationMonitor\n",
    "cfg = {\n",
    "    'Sim': { 'use_cupy': True, 'esno_db_range': np.array(esno_db_range), 'num_slots': num_slots },\n",
    "    'Frame': { 'num_ofdm_symbols': num_ofdm_symbols, 'fft_size': fft_size, 'cyclic_prefix_length': cyclic_prefix_length, 'subcarrier_spacing': subcarrier_spacing },\n",
    "    'System': { 'num_tx_ant': num_tx_ant, 'num_rx_ant': num_rx_ant, 'cell_id': cell_id },\n",
    "    'PUSCH': { 'num_prbs': num_prbs, 'mcs_index': mcs_index, 'mcs_table': mcs_table, 'tb_size_bits': int(tb_size) },\n",
    "    'Channel': { 'carrier_frequency': carrier_frequency, 'channel_model': channel_model },\n",
    "    'Algo': { 'use_trt': True }\n",
    "}\n",
    "monitor = SimulationMonitor(cases, esno_db_range, config=cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf738283",
   "metadata": {},
   "source": [
    "## Channel generation using Sionna\n",
    "Simulating the transmission through the radio channel takes advantage of the channel model implementations available in NVIDIA Sionna. In Sionna, the transmission can be simulated directly in frequency domain by defining a resource grid. In our case, reference signal patterns and data carrying resource elements are defined elsewhere within the Aerial code, hence we define resource grid as a simple dummy grid containing only data symbols.\n",
    "\n",
    "See also: [Sionna documentation](https://nvlabs.github.io/sionna/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ae80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resource grid.\n",
    "resource_grid = sionna.phy.ofdm.ResourceGrid(\n",
    "    num_ofdm_symbols=num_ofdm_symbols,\n",
    "    fft_size=fft_size,\n",
    "    subcarrier_spacing=subcarrier_spacing,\n",
    "    num_tx=1,\n",
    "    num_streams_per_tx=1,\n",
    "    cyclic_prefix_length=cyclic_prefix_length,\n",
    "    num_guard_carriers=num_guard_subcarriers,\n",
    "    dc_null=False,\n",
    "    pilot_pattern=None,\n",
    "    pilot_ofdm_symbol_indices=None\n",
    ")\n",
    "resource_grid_mapper = sionna.phy.ofdm.ResourceGridMapper(resource_grid)\n",
    "remove_guard_subcarriers = sionna.phy.ofdm.RemoveNulledSubcarriers(resource_grid)\n",
    "\n",
    "# Define the antenna arrays.\n",
    "ue_array = sionna.phy.channel.tr38901.Antenna(\n",
    "    polarization=\"single\",\n",
    "    polarization_type=\"V\",\n",
    "    antenna_pattern=\"38.901\",\n",
    "    carrier_frequency=carrier_frequency\n",
    ")\n",
    "gnb_array = sionna.phy.channel.tr38901.AntennaArray(\n",
    "    num_rows=1,\n",
    "    num_cols=int(num_rx_ant/2),\n",
    "    polarization=\"dual\",\n",
    "    polarization_type=\"cross\",\n",
    "    antenna_pattern=\"38.901\",\n",
    "    carrier_frequency=carrier_frequency\n",
    ")\n",
    "\n",
    "if channel_model == \"Rayleigh\":\n",
    "    ch_model = sionna.phy.channel.RayleighBlockFading(\n",
    "        num_rx=1,\n",
    "        num_rx_ant=num_rx_ant,\n",
    "        num_tx=1,\n",
    "        num_tx_ant=num_tx_ant\n",
    "    )\n",
    "    \n",
    "elif \"CDL\" in channel_model:\n",
    "    cdl_model = channel_model[-1]\n",
    "    \n",
    "    # Configure a channel impulse reponse (CIR) generator for the CDL model.\n",
    "    ch_model = sionna.phy.channel.tr38901.CDL(\n",
    "        cdl_model,\n",
    "        delay_spread,\n",
    "        carrier_frequency,\n",
    "        ue_array,\n",
    "        gnb_array,\n",
    "        link_direction,\n",
    "        min_speed=speed\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Invalid channel model {channel_model}!\")\n",
    "\n",
    "channel = sionna.phy.channel.OFDMChannel(\n",
    "    ch_model,\n",
    "    resource_grid,\n",
    "    add_awgn=True,\n",
    "    normalize_channel=True,\n",
    "    return_channel=False\n",
    ")\n",
    "\n",
    "def apply_channel(tx_tensor, No):\n",
    "    \"\"\"Transmit the Tx tensor through the radio channel.\"\"\"\n",
    "    # Add batch and num_tx dimensions that Sionna expects and reshape.\n",
    "    tx_tensor = tf.transpose(tx_tensor, (2, 1, 0))\n",
    "    tx_tensor = tf.reshape(tx_tensor, (1, -1))[None, None]        \n",
    "    tx_tensor = resource_grid_mapper(tx_tensor)\n",
    "    rx_tensor = channel(tx_tensor, No)\n",
    "    rx_tensor = remove_guard_subcarriers(rx_tensor)\n",
    "    rx_tensor = rx_tensor[0, 0]\n",
    "    rx_tensor = tf.transpose(rx_tensor, (2, 1, 0))\n",
    "    return rx_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ac5e32",
   "metadata": {},
   "source": [
    "## Run the actual simulation\n",
    "Here we loop across the Es/No range, and simulate a number of slots for each Es/No value. A single transport block is simulated within a slot. The simulation starts over from the next Es/No value when a minimum number of transport block errors is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cc4852",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = [\"PUSCH Rx\", \"Neural Rx\"]\n",
    "monitor = SimulationMonitor(cases, esno_db_range, config=cfg)\n",
    "\n",
    "# Loop the Es/No range.\n",
    "bler = []\n",
    "for esno_db in esno_db_range:\n",
    "    monitor.step(esno_db)\n",
    "    num_tb_errors = defaultdict(int)\n",
    "    \n",
    "    # Run multiple slots and compute BLER.\n",
    "    for slot_idx in range(num_slots):\n",
    "        slot_number = slot_idx % num_slots_per_frame                \n",
    "        \n",
    "        # Get modulation order and coderate.\n",
    "        tb_input_np = random_tb(\n",
    "            mod_order=mod_order,\n",
    "            code_rate=code_rate,\n",
    "            dmrs_syms=dmrs_syms,\n",
    "            num_prbs=num_prbs,\n",
    "            start_sym=start_sym,\n",
    "            num_symbols=num_symbols,\n",
    "            num_layers=layers)\n",
    "        tb_input = cp.array(tb_input_np, dtype=cp.uint8, order='F')\n",
    "        \n",
    "        # Transmit PUSCH. This is where we set the dynamically changing parameters.\n",
    "        # Input parameters are given as lists as the interface supports multiple UEs.\n",
    "        tx_tensor = pusch_tx.run(\n",
    "            tb_inputs=[tb_input],          # Input transport block in bytes.           \n",
    "            num_ues=1,                     # We simulate only one UE here.\n",
    "            slot=slot_number,              # Slot number.\n",
    "            num_dmrs_cdm_grps_no_data=num_dmrs_cdm_grps_no_data,\n",
    "            dmrs_scrm_ids=[dmrs_scrm_id],  # DMRS scrambling ID.\n",
    "            start_prb=start_prb,           # Start PRB index.\n",
    "            num_prbs=num_prbs,             # Number of allocated PRBs.\n",
    "            dmrs_syms=dmrs_syms,           # List of binary numbers indicating which symbols are DMRS.\n",
    "            start_sym=start_sym,           # Start symbol index.\n",
    "            num_symbols=num_symbols,       # Number of symbols.\n",
    "            scids=[scid],                  # DMRS scrambling ID.\n",
    "            layers=[layers],               # Number of layers (transmission rank).\n",
    "            dmrs_ports=[dmrs_ports],       # DMRS port(s) to be used.\n",
    "            rntis=[rnti],                  # UE RNTI.\n",
    "            data_scids=[data_scid],        # Data scrambling ID.\n",
    "            code_rates=[code_rate * 10],   # Code rate x 1024 x 10.\n",
    "            mod_orders=[mod_order]         # Modulation order.            \n",
    "        )\n",
    "                \n",
    "        # Channel transmission using TF and Sionna.\n",
    "        tx_tensor = tf.experimental.dlpack.from_dlpack(tx_tensor.toDlpack())\n",
    "        No = pow(10., -esno_db / 10.)\n",
    "        rx_tensor = apply_channel(tx_tensor, No)\n",
    "        rx_tensor = tf.experimental.dlpack.to_dlpack(rx_tensor)\n",
    "        rx_tensor = cp.from_dlpack(rx_tensor)        \n",
    "        \n",
    "        # Run the fused PUSCH receiver.\n",
    "        # Note that this is where we set the dynamically changing parameters.\n",
    "        tb_crcs, tbs = pusch_rx.run(\n",
    "            rx_slot=rx_tensor,           \n",
    "            slot=slot_number,\n",
    "            pusch_configs=pusch_configs\n",
    "        )\n",
    "        num_tb_errors[\"PUSCH Rx\"] += int(np.array_equal(tbs[0], tb_input_np) == False)\n",
    "        \n",
    "        # Run the neural receiver.\n",
    "        tbs = neural_rx.run(\n",
    "            rx_slot=rx_tensor,\n",
    "            slot=slot_number,\n",
    "            pusch_configs=pusch_configs\n",
    "        )\n",
    "        num_tb_errors[\"Neural Rx\"] += int(np.array_equal(tbs[0], tb_input_np) == False)\n",
    "\n",
    "        monitor.update(num_tbs=slot_idx + 1, num_tb_errors=num_tb_errors)\n",
    "        if (np.array(list(num_tb_errors.values())) >= min_num_tb_errors).all():\n",
    "            break  # Next Es/No value.\n",
    "    \n",
    "    monitor.finish_step(num_tbs=slot_idx + 1, num_tb_errors=num_tb_errors)  \n",
    "monitor.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
